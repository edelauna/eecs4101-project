{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Policy Search\n",
    "\n",
    "<h2 id=\"tocheading\">Index</h2>\n",
    "<div id=\"toc\"></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Guided Policy Search (GPS) is a technique that transforms the Reinforcement Learning (RL) task of policy search into a Supervised Learning problem, where the training set is generated by a simple trajectory-centric RL algorithm. \n",
    "\n",
    "This algorithm optimizes linear-Gaussian controllers $p_i (u_t | x_t)$. Each $p_i (u_t | x_t)$ succeeds in the task from different initial states which helps the algorithm to generalize to other states from the same distribution. The final policy $\\pi_\\theta(u_t | o_t )$ learned with GPS is only provided with observations $o_t$ of the full state $x_t$, and assumed dynamics are assumed to be unknown. \n",
    "\n",
    "![](gps_illustration.png)\n",
    "\n",
    "We draw sample trajectories $\\tau_i^j$ for each initial state on the physical system by running the corresponding controller $p_i(u_t | x_t)$. The samples are used to fit the dynamics $p_i (x_{t+1} | x_t, u_t)$ that are used to improve the controllers $p_i(u_t | x_t)$, and serve as training data for the policy $\\pi_\\theta(u_t | o_t )$. Within the graph we can observe how there's a loop that alternates between optimizing each trajectory distribution $p_i (\\tau)$ and optimizing the policy $\\pi_\\theta(u_t | o_t )$ to match these trajectory distributions.\n",
    "\n",
    "\n",
    "This work is based on https://arxiv.org/abs/1504.00702. Refer to http://rll.berkeley.edu/gps/ for the original implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions and notations\n",
    "\n",
    "| corresponding symbol | definition |\n",
    "|--------|------------|\n",
    "| $p_i(u_t | x_t)$ | linear-Gaussian controllers |\n",
    "| $\\pi_\\theta(u_t | o_t )$| final policy learned |\n",
    "| $p_i (\\tau)$| trajectory distribution induced from the linear-Gaussian controllers, guiding distribution |\n",
    "| $\\tau_i^j$ | sample trajectories, sampled from the distribution |\n",
    "| $o_t$ | observations |\n",
    "| $x_t$ | full state |\n",
    "| $p_i (x_{t+1} | x_t, u_t)$ | dynamics |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test environment\n",
    "The following test environment will be used for the purpose of implementing GPS.\n",
    "\n",
    "![](gps_testenv.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-17 12:43:38,300] Making new env: Pendulum-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('Pendulum-v0')\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample()) # take a random action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPS implementation\n",
    "\n",
    "### Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import abc\n",
    "import numpy as np\n",
    "\n",
    "class Dynamics(object):\n",
    "    \"\"\" Dynamics superclass. \"\"\"\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "\n",
    "    def __init__(self, hyperparams):\n",
    "        self._hyperparams = hyperparams\n",
    "\n",
    "        # TODO - Currently assuming that dynamics will always be linear\n",
    "        #        with X.\n",
    "        # TODO - Allocate arrays using hyperparams dU, dX, T.\n",
    "\n",
    "        # Fitted dynamics: x_t+1 = Fm * [x_t;u_t] + fv.\n",
    "        self.Fm = np.array(np.nan)\n",
    "        self.fv = np.array(np.nan)\n",
    "        self.dyn_covar = np.array(np.nan)  # Covariance.\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def update_prior(self, sample):\n",
    "        \"\"\" Update dynamics prior. \"\"\"\n",
    "        raise NotImplementedError(\"Must be implemented in subclass.\")\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_prior(self):\n",
    "        \"\"\" Returns prior object. \"\"\"\n",
    "        raise NotImplementedError(\"Must be implemented in subclass.\")\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def fit(self, sample_list):\n",
    "        \"\"\" Fit dynamics. \"\"\"\n",
    "        raise NotImplementedError(\"Must be implemented in subclass.\")\n",
    "\n",
    "    def copy(self):\n",
    "        \"\"\" Return a copy of the dynamics estimate. \"\"\"\n",
    "        dyn = type(self)(self._hyperparams)\n",
    "        dyn.Fm = np.copy(self.Fm)\n",
    "        dyn.fv = np.copy(self.fv)\n",
    "        dyn.dyn_covar = np.copy(self.dyn_covar)\n",
    "        return dyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
